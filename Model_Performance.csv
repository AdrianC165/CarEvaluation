Hyperparameters,Train Accuracy,Train Error,Test Accuracy,Test Error
"Activation=logistic, LR=0.01, Epochs=100, Layers=2",0.822,0.178,0.818,0.182
"Activation=logistic, LR=0.01, Epochs=100, Layers=3",0.832,0.168,0.815,0.185
"Activation=logistic, LR=0.01, Epochs=200, Layers=2",0.834,0.166,0.824,0.176
"Activation=logistic, LR=0.01, Epochs=200, Layers=3",0.846,0.154,0.828,0.172
"Activation=logistic, LR=0.1, Epochs=100, Layers=2",0.853,0.147,0.828,0.172
"Activation=logistic, LR=0.1, Epochs=100, Layers=3",0.918,0.082,0.892,0.108
"Activation=logistic, LR=0.1, Epochs=200, Layers=2",0.877,0.123,0.873,0.127
"Activation=logistic, LR=0.1, Epochs=200, Layers=3",0.911,0.089,0.9,0.1
"Activation=tanh, LR=0.01, Epochs=100, Layers=2",0.785,0.215,0.786,0.214
"Activation=tanh, LR=0.01, Epochs=100, Layers=3",0.878,0.122,0.88,0.12
"Activation=tanh, LR=0.01, Epochs=200, Layers=2",0.785,0.215,0.785,0.215
"Activation=tanh, LR=0.01, Epochs=200, Layers=3",0.883,0.117,0.88,0.12
"Activation=tanh, LR=0.1, Epochs=100, Layers=2",0.84,0.16,0.828,0.172
"Activation=tanh, LR=0.1, Epochs=100, Layers=3",0.824,0.176,0.821,0.179
"Activation=tanh, LR=0.1, Epochs=200, Layers=2",0.694,0.306,0.71,0.29
"Activation=tanh, LR=0.1, Epochs=200, Layers=3",0.872,0.128,0.855,0.145
"Activation=relu, LR=0.01, Epochs=100, Layers=2",0.802,0.198,0.793,0.207
"Activation=relu, LR=0.01, Epochs=100, Layers=3",0.838,0.162,0.816,0.184
"Activation=relu, LR=0.01, Epochs=200, Layers=2",0.842,0.158,0.825,0.175
"Activation=relu, LR=0.01, Epochs=200, Layers=3",0.923,0.077,0.912,0.088
"Activation=relu, LR=0.1, Epochs=100, Layers=2",0.793,0.207,0.798,0.202
"Activation=relu, LR=0.1, Epochs=100, Layers=3",0.795,0.205,0.795,0.205
"Activation=relu, LR=0.1, Epochs=200, Layers=2",0.858,0.142,0.835,0.165
"Activation=relu, LR=0.1, Epochs=200, Layers=3",0.838,0.162,0.811,0.189
